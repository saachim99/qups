//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31294372
// Cuda compilation tools, release 11.7, V11.7.64
// Based on NVVM 7.0.1
//

.version 7.7
.target sm_50
.address_size 64

	// .globl	_Z5convfPKfS0_Pf
.const .align 8 .u64 M;
.const .align 8 .u64 N;
.const .align 8 .u64 L;
.const .align 4 .u32 L0;

.visible .entry _Z5convfPKfS0_Pf(
	.param .u64 _Z5convfPKfS0_Pf_param_0,
	.param .u64 _Z5convfPKfS0_Pf_param_1,
	.param .u64 _Z5convfPKfS0_Pf_param_2
)
{
	.reg .pred 	%p<11>;
	.reg .f32 	%f<12>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<27>;


	ld.param.u64 	%rd12, [_Z5convfPKfS0_Pf_param_0];
	ld.param.u64 	%rd13, [_Z5convfPKfS0_Pf_param_1];
	ld.param.u64 	%rd14, [_Z5convfPKfS0_Pf_param_2];
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.y;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %tid.y;
	mad.lo.s32 	%r13, %r11, %r10, %r12;
	cvt.u64.u32 	%rd1, %r13;
	cvt.s64.s32 	%rd2, %r9;
	ld.const.u64 	%rd3, [L];
	setp.le.u64 	%p1, %rd3, %rd2;
	mov.f32 	%f9, 0f00000000;
	@%p1 bra 	$L__BB0_3;

	cvt.u32.u64 	%r15, %rd2;
	ld.const.u32 	%r16, [L0];
	sub.s32 	%r21, %r16, %r15;
	ld.const.u64 	%rd4, [M];
	mul.lo.s64 	%rd5, %rd4, %rd1;
	ld.const.u64 	%rd6, [N];
	mul.lo.s64 	%rd7, %rd6, %rd1;
	cvta.to.global.u64 	%rd8, %rd12;
	cvta.to.global.u64 	%rd9, %rd13;
	mov.u32 	%r20, 0;
	mov.f32 	%f9, 0f00000000;
	bra.uni 	$L__BB0_2;

$L__BB0_8:
	cvt.u32.u64 	%r18, %rd10;
	add.s32 	%r20, %r18, 1;
	add.s32 	%r21, %r17, 1;

$L__BB0_2:
	cvt.u64.u32 	%rd10, %r20;
	setp.gt.u64 	%p2, %rd4, %rd10;
	cvt.s64.s32 	%rd11, %r21;
	setp.gt.u64 	%p3, %rd6, %rd11;
	or.pred  	%p4, %p2, %p3;
	@%p4 bra 	$L__BB0_6;
	bra.uni 	$L__BB0_3;

$L__BB0_6:
	cvt.u32.u64 	%r17, %rd11;
	setp.lt.s32 	%p6, %r17, 0;
	setp.le.u64 	%p7, %rd4, %rd10;
	or.pred  	%p8, %p6, %p7;
	setp.le.u64 	%p9, %rd6, %rd11;
	or.pred  	%p10, %p8, %p9;
	@%p10 bra 	$L__BB0_8;

	cvt.s64.s32 	%rd20, %rd10;
	add.s64 	%rd21, %rd5, %rd20;
	shl.b64 	%rd22, %rd21, 2;
	add.s64 	%rd23, %rd8, %rd22;
	add.s64 	%rd24, %rd7, %rd11;
	shl.b64 	%rd25, %rd24, 2;
	add.s64 	%rd26, %rd9, %rd25;
	ld.global.f32 	%f7, [%rd26];
	ld.global.f32 	%f8, [%rd23];
	fma.rn.ftz.f32 	%f9, %f8, %f7, %f9;
	bra.uni 	$L__BB0_8;

$L__BB0_3:
	@%p1 bra 	$L__BB0_5;

	mul.lo.s64 	%rd15, %rd3, %rd1;
	add.s64 	%rd16, %rd15, %rd2;
	cvta.to.global.u64 	%rd17, %rd14;
	shl.b64 	%rd18, %rd16, 2;
	add.s64 	%rd19, %rd17, %rd18;
	st.global.f32 	[%rd19], %f9;

$L__BB0_5:
	ret;

}
	// .globl	_Z4convPKdS0_Pd
.visible .entry _Z4convPKdS0_Pd(
	.param .u64 _Z4convPKdS0_Pd_param_0,
	.param .u64 _Z4convPKdS0_Pd_param_1,
	.param .u64 _Z4convPKdS0_Pd_param_2
)
{
	.reg .pred 	%p<11>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<12>;
	.reg .b64 	%rd<27>;


	ld.param.u64 	%rd12, [_Z4convPKdS0_Pd_param_0];
	ld.param.u64 	%rd13, [_Z4convPKdS0_Pd_param_1];
	ld.param.u64 	%rd14, [_Z4convPKdS0_Pd_param_2];
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.y;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %tid.y;
	mad.lo.s32 	%r13, %r11, %r10, %r12;
	cvt.u64.u32 	%rd1, %r13;
	cvt.s64.s32 	%rd2, %r9;
	ld.const.u64 	%rd3, [L];
	setp.le.u64 	%p1, %rd3, %rd2;
	mov.f64 	%fd9, 0d0000000000000000;
	@%p1 bra 	$L__BB1_3;

	cvt.u32.u64 	%r15, %rd2;
	ld.const.u32 	%r16, [L0];
	sub.s32 	%r21, %r16, %r15;
	ld.const.u64 	%rd4, [M];
	mul.lo.s64 	%rd5, %rd4, %rd1;
	ld.const.u64 	%rd6, [N];
	mul.lo.s64 	%rd7, %rd6, %rd1;
	cvta.to.global.u64 	%rd8, %rd12;
	cvta.to.global.u64 	%rd9, %rd13;
	mov.u32 	%r20, 0;
	mov.f64 	%fd9, 0d0000000000000000;
	bra.uni 	$L__BB1_2;

$L__BB1_8:
	cvt.u32.u64 	%r18, %rd10;
	add.s32 	%r20, %r18, 1;
	add.s32 	%r21, %r17, 1;

$L__BB1_2:
	cvt.u64.u32 	%rd10, %r20;
	setp.gt.u64 	%p2, %rd4, %rd10;
	cvt.s64.s32 	%rd11, %r21;
	setp.gt.u64 	%p3, %rd6, %rd11;
	or.pred  	%p4, %p2, %p3;
	@%p4 bra 	$L__BB1_6;
	bra.uni 	$L__BB1_3;

$L__BB1_6:
	cvt.u32.u64 	%r17, %rd11;
	setp.lt.s32 	%p6, %r17, 0;
	setp.le.u64 	%p7, %rd4, %rd10;
	or.pred  	%p8, %p6, %p7;
	setp.le.u64 	%p9, %rd6, %rd11;
	or.pred  	%p10, %p8, %p9;
	@%p10 bra 	$L__BB1_8;

	cvt.s64.s32 	%rd20, %rd10;
	add.s64 	%rd21, %rd5, %rd20;
	shl.b64 	%rd22, %rd21, 3;
	add.s64 	%rd23, %rd8, %rd22;
	add.s64 	%rd24, %rd7, %rd11;
	shl.b64 	%rd25, %rd24, 3;
	add.s64 	%rd26, %rd9, %rd25;
	ld.global.f64 	%fd7, [%rd26];
	ld.global.f64 	%fd8, [%rd23];
	fma.rn.f64 	%fd9, %fd8, %fd7, %fd9;
	bra.uni 	$L__BB1_8;

$L__BB1_3:
	@%p1 bra 	$L__BB1_5;

	mul.lo.s64 	%rd15, %rd3, %rd1;
	add.s64 	%rd16, %rd15, %rd2;
	cvta.to.global.u64 	%rd17, %rd14;
	shl.b64 	%rd18, %rd16, 3;
	add.s64 	%rd19, %rd17, %rd18;
	st.global.f64 	[%rd19], %fd9;

$L__BB1_5:
	ret;

}
	// .globl	_Z6convcfPK6float2S1_PS_
.visible .entry _Z6convcfPK6float2S1_PS_(
	.param .u64 _Z6convcfPK6float2S1_PS__param_0,
	.param .u64 _Z6convcfPK6float2S1_PS__param_1,
	.param .u64 _Z6convcfPK6float2S1_PS__param_2
)
{
	.reg .pred 	%p<11>;
	.reg .f32 	%f<32>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<27>;


	ld.param.u64 	%rd12, [_Z6convcfPK6float2S1_PS__param_0];
	ld.param.u64 	%rd13, [_Z6convcfPK6float2S1_PS__param_1];
	ld.param.u64 	%rd14, [_Z6convcfPK6float2S1_PS__param_2];
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.y;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %tid.y;
	mad.lo.s32 	%r13, %r11, %r10, %r12;
	cvt.u64.u32 	%rd1, %r13;
	cvt.s64.s32 	%rd2, %r9;
	ld.const.u64 	%rd3, [L];
	setp.le.u64 	%p1, %rd3, %rd2;
	mov.f32 	%f26, 0f00000000;
	mov.f32 	%f27, %f26;
	@%p1 bra 	$L__BB2_3;

	cvt.u32.u64 	%r15, %rd2;
	ld.const.u32 	%r16, [L0];
	sub.s32 	%r21, %r16, %r15;
	ld.const.u64 	%rd4, [M];
	mul.lo.s64 	%rd5, %rd4, %rd1;
	ld.const.u64 	%rd6, [N];
	mul.lo.s64 	%rd7, %rd6, %rd1;
	cvta.to.global.u64 	%rd8, %rd12;
	cvta.to.global.u64 	%rd9, %rd13;
	mov.u32 	%r20, 0;
	mov.f32 	%f26, 0f00000000;
	bra.uni 	$L__BB2_2;

$L__BB2_8:
	cvt.u32.u64 	%r18, %rd10;
	add.s32 	%r20, %r18, 1;
	add.s32 	%r21, %r17, 1;

$L__BB2_2:
	cvt.u64.u32 	%rd10, %r20;
	setp.gt.u64 	%p2, %rd4, %rd10;
	cvt.s64.s32 	%rd11, %r21;
	setp.gt.u64 	%p3, %rd6, %rd11;
	or.pred  	%p4, %p2, %p3;
	@%p4 bra 	$L__BB2_6;
	bra.uni 	$L__BB2_3;

$L__BB2_6:
	cvt.u32.u64 	%r17, %rd11;
	setp.lt.s32 	%p6, %r17, 0;
	setp.le.u64 	%p7, %rd4, %rd10;
	or.pred  	%p8, %p6, %p7;
	setp.le.u64 	%p9, %rd6, %rd11;
	or.pred  	%p10, %p8, %p9;
	@%p10 bra 	$L__BB2_8;

	cvt.s64.s32 	%rd20, %rd10;
	add.s64 	%rd21, %rd5, %rd20;
	shl.b64 	%rd22, %rd21, 3;
	add.s64 	%rd23, %rd8, %rd22;
	ld.global.v2.f32 	{%f13, %f14}, [%rd23];
	add.s64 	%rd24, %rd7, %rd11;
	shl.b64 	%rd25, %rd24, 3;
	add.s64 	%rd26, %rd9, %rd25;
	ld.global.v2.f32 	{%f17, %f18}, [%rd26];
	mul.ftz.f32 	%f21, %f14, %f18;
	fma.rn.ftz.f32 	%f22, %f13, %f17, %f21;
	mul.ftz.f32 	%f23, %f13, %f18;
	mul.ftz.f32 	%f24, %f14, %f17;
	sub.ftz.f32 	%f25, %f24, %f23;
	add.ftz.f32 	%f27, %f27, %f22;
	add.ftz.f32 	%f26, %f26, %f25;
	bra.uni 	$L__BB2_8;

$L__BB2_3:
	@%p1 bra 	$L__BB2_5;

	mul.lo.s64 	%rd15, %rd3, %rd1;
	add.s64 	%rd16, %rd15, %rd2;
	cvta.to.global.u64 	%rd17, %rd14;
	shl.b64 	%rd18, %rd16, 3;
	add.s64 	%rd19, %rd17, %rd18;
	st.global.v2.f32 	[%rd19], {%f27, %f26};

$L__BB2_5:
	ret;

}
	// .globl	_Z5convcPK7double2S1_PS_
.visible .entry _Z5convcPK7double2S1_PS_(
	.param .u64 _Z5convcPK7double2S1_PS__param_0,
	.param .u64 _Z5convcPK7double2S1_PS__param_1,
	.param .u64 _Z5convcPK7double2S1_PS__param_2
)
{
	.reg .pred 	%p<11>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<32>;
	.reg .b64 	%rd<27>;


	ld.param.u64 	%rd12, [_Z5convcPK7double2S1_PS__param_0];
	ld.param.u64 	%rd13, [_Z5convcPK7double2S1_PS__param_1];
	ld.param.u64 	%rd14, [_Z5convcPK7double2S1_PS__param_2];
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.y;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %tid.y;
	mad.lo.s32 	%r13, %r11, %r10, %r12;
	cvt.u64.u32 	%rd1, %r13;
	cvt.s64.s32 	%rd2, %r9;
	ld.const.u64 	%rd3, [L];
	setp.le.u64 	%p1, %rd3, %rd2;
	mov.f64 	%fd26, 0d0000000000000000;
	mov.f64 	%fd27, %fd26;
	@%p1 bra 	$L__BB3_3;

	cvt.u32.u64 	%r15, %rd2;
	ld.const.u32 	%r16, [L0];
	sub.s32 	%r21, %r16, %r15;
	ld.const.u64 	%rd4, [M];
	mul.lo.s64 	%rd5, %rd4, %rd1;
	ld.const.u64 	%rd6, [N];
	mul.lo.s64 	%rd7, %rd6, %rd1;
	cvta.to.global.u64 	%rd8, %rd12;
	cvta.to.global.u64 	%rd9, %rd13;
	mov.u32 	%r20, 0;
	mov.f64 	%fd26, 0d0000000000000000;
	bra.uni 	$L__BB3_2;

$L__BB3_8:
	cvt.u32.u64 	%r18, %rd10;
	add.s32 	%r20, %r18, 1;
	add.s32 	%r21, %r17, 1;

$L__BB3_2:
	cvt.u64.u32 	%rd10, %r20;
	setp.gt.u64 	%p2, %rd4, %rd10;
	cvt.s64.s32 	%rd11, %r21;
	setp.gt.u64 	%p3, %rd6, %rd11;
	or.pred  	%p4, %p2, %p3;
	@%p4 bra 	$L__BB3_6;
	bra.uni 	$L__BB3_3;

$L__BB3_6:
	cvt.u32.u64 	%r17, %rd11;
	setp.lt.s32 	%p6, %r17, 0;
	setp.le.u64 	%p7, %rd4, %rd10;
	or.pred  	%p8, %p6, %p7;
	setp.le.u64 	%p9, %rd6, %rd11;
	or.pred  	%p10, %p8, %p9;
	@%p10 bra 	$L__BB3_8;

	cvt.s64.s32 	%rd20, %rd10;
	add.s64 	%rd21, %rd5, %rd20;
	shl.b64 	%rd22, %rd21, 4;
	add.s64 	%rd23, %rd8, %rd22;
	ld.global.v2.f64 	{%fd13, %fd14}, [%rd23];
	add.s64 	%rd24, %rd7, %rd11;
	shl.b64 	%rd25, %rd24, 4;
	add.s64 	%rd26, %rd9, %rd25;
	ld.global.v2.f64 	{%fd17, %fd18}, [%rd26];
	mul.f64 	%fd21, %fd14, %fd18;
	fma.rn.f64 	%fd22, %fd13, %fd17, %fd21;
	mul.f64 	%fd23, %fd13, %fd18;
	mul.f64 	%fd24, %fd14, %fd17;
	sub.f64 	%fd25, %fd24, %fd23;
	add.f64 	%fd27, %fd27, %fd22;
	add.f64 	%fd26, %fd26, %fd25;
	bra.uni 	$L__BB3_8;

$L__BB3_3:
	@%p1 bra 	$L__BB3_5;

	mul.lo.s64 	%rd15, %rd3, %rd1;
	add.s64 	%rd16, %rd15, %rd2;
	cvta.to.global.u64 	%rd17, %rd14;
	shl.b64 	%rd18, %rd16, 4;
	add.s64 	%rd19, %rd17, %rd18;
	st.global.v2.f64 	[%rd19], {%fd27, %fd26};

$L__BB3_5:
	ret;

}

